---
title: "Use of forecasting models for improved PID control in wastewater treatment"
author: "Kathryn B. Newhart"
output:
  word_document:
    toc: yes
    toc_depth: 3
    df_print: paged
    reference_docx: final_paper_reference.docx
  html_document:
    df_print: paged
    fig_caption: no
    number_sections: yes
    toc: yes
    toc_depth: 3
bibliography: bibliography.bib
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path="figures/", fig.align="center", fig.fullwidth=TRUE, fig.width=6.5, dpi=300,
                      echo=FALSE, warning=FALSE, message=FALSE)
    # 
```

`r fig<-0;tab<-0`

```{r}
timeseries <- function(data, title) {
  run.time <- as.numeric(difftime(index(data), index(data)[1], units="days"))
  plot.data <- as.numeric(data)
  plot(x = run.time, y = plot.data, 
       main=title, 
       xlab="", ylab="", ylim=c(0,10),
       pch=20, cex.axis = 1.25)
}
```

# Introduction 

One of the greatest and costliest threats to surface waterways in the United States is nutrient pollution [@usepa2011working]. The removal of nitrogen and phosphorus from municipal wastewater treatment plant (WWTP) discharges is necessary to address the growing environmental challenge of increased nitrogen and phosphorus. As states implement increasingly stringint nutrient limits on WWTP, the cost of wastewater treatment is increasing substancially. For example, biological removal of nitrogen and phosphorus is acheived by introducing dissolved oxygen (DO) via industrial-sized air blowers, which is one of the largest operating costs in WWTP. Conventionally, air blower speed is increased or decreased relative to the measured concentration of DO in an aeration basin. While this approach can guarentee that nitrogen is removed (i.e., converted from ammonia and other organic nitrogen species to nitrate, and in a subsequent step nitrogen gas), it is inefficient as aeration is provided whether ammonia is present or absent, wasting energy; experience large fluctuations in air demand to maintain a single DO setpoint, which mechanically stresses the air blowers; and stresses the microbial communities responsible for wastewater treatment with large and rapid DO fluctuations. WWTP operators rely on trial-and-error to identify a DO setpoint that treats water to an ammonia concentration well below their permited limit. The large factor of safety is required to ensure that even under the highest flow and load conditions, the WWTP will not exceed their nitrogen limit. To save energy and reduce excessive use of air blowers at WWTP, a new aeration paradigm is needed. 

Ammonia-based aeration control (ABAC) is an aeration approach which responds to water quality changes in real time by adjusting air flow to meet an ammonia setpoint, instead of a DO setpoint. ABAC can limit aeration, to prevent complete ammonia conversion, increase nitrate conversion, and potentially improve phosphorus removal, and reduce effluent ammonia peaks [@rieger_myths_2012]. 

The most frquently used ABAC configuration utilizes a microbial kinetic model to calculate the aeration demand given a variety of operating parameters such as solids retention time and influent ammonia concentration [@duffy2010dissolved]. This feedforward approach requires entensive sampling and specialized knowledge for accurate model calibration. A feedback ABAC option would not require a kinetic model, and simply adjust DO setpoints from an ammonia sensor in the aeration basin. However, WWTP operators can be hesitent to adopt ABAC due to the instability of ABAC sensors (specifically ion-selective electrodes) and the potential for the growth of microorganisms that inhibit settling in subsequent treatment at lower DO concentrations. A third approach would incorporate statistical process models to predict ammonia. Existing hurdles to implementation of data-driven systems in WWTP include knowledge and experience. To date, there are only a handful of WWTP in and outside of the U.S. who have implemented MPCA systems in their facilities.

The goal of this work is to (1) demonstrate the stability of a feedback ABAC configuration for WWTP operators and (2) explore simple, data-driven methods of forecasting ammonia to overcome the lag associated with conventional feedback control to *improve accuracy* and *reduce mechanical wear* of aeration systems. Four different cascade control aeration configurations are compared to identify the *most stable* (i.e., least variable) operating condition--this will assist WWTP operators in maintaining a low concentration of ammonia in the treated water and test the robustness of forecasting methods. The advantages of forecasting using statistical and machine learning models is (a) no additional sampling, microbiological analysis, or proprietary software is requried to build the model and (b) the forecast can easily replace the current measured value of ammonia in the supervisory control and data aquisition (SCADA) system of the WWTP--which lacks advanced control schema. The manuscript is organized as follows: (1) an introduction to control systems in WWTP, (2) summary of methods for quantifying variation in multivariate systems, (3) summary of staistical and machine learning methods used to build the ammonia forecasting models, and (4) an assessment of how forecasting models can improve conventional control in WWTP. 


## Control in wastewater treatment

WWTP are similar to other industrial processes in that select monitored system parameters need to be within a set range for the system to operate properly. Unlike many industrial processes, municipal WWTP have little control over the quantity and quality of the inputs to their system but are required by law to maintain a certain quality of the output.  Due to the wide variation, manual adjustments of an open-loop control system (i.e., constant control output regardless of system conditions) cannot constantly achieve the level of treatment needed; frequently under-treating during peak flows and potentially exceeding regulated quality limits, and over-treating during low flows which wastes energy and other material inputs. Therefore, a flexible and responsive control system is required to maintain effluent water quality while minimizing energy and chemical input. 

Feedback control determines a control action from a process measurement within the system (i.e., closed-loop control), and is able to automatically respond to system disturbances without specific knowledge of how the control and response parameters are related. The Proprotional-Integral-Derivative (PID) controller is the most common feedback controller in industrial automation due to it's simplisity and robustness to respond to a deviation from desired conditions (i.e., error $e(t)$). A PID control action is the sum of: a proportional term ($K_p(e(t))$) where $K_p$ is a constant value; a integral term ($K_i \int_{0}^{t} e(\tau) d\tau$) and incorporates past control error with the integral function; and a derivative term ($K_d \frac{de(t)}{dt}$) which anticipates future error with the derivative function. In the wastewater treatment industry, the derivative term is frequently set to 0 (i.e., PI control) due to the amplification of noise in the measured variable [@visioli2006practical]. 

A single PID control loop can address straightforward problems, such as adjusting the speed of a blower or pump relative to a sensor measurement. To address more complex, nonlinear problems, multiple PID control loops can be combined in series to form a cascade control structure[@brosilow2002techniques]. In the case of ABAC, an ammonia sensor and setpoint define the outer/master control loop while inner/slave control loops define control variables such as DO, air blower flow, air blower speed, etc. In controller design, actuator and sensor dynamics and wear-and-tear are frequently ignored [@visioli2006practical]. For aeration at WWTP, this leads to a delay between a change in demand and the aeration provided, and excessive ramping of the air blower as a result of the delay.  

# Methods and Materials

## Boulder Water Resource Recovery Facility
The Boulder Water Resource Recovery Facility (BWRRF, Boulder, Colorado, USA) is a 25 million gallon per day (MGD) municipal WWTP, currently operating a Four-Stage Bardenpho process at an average of 12 MGD. Given the high altitude of the facility and low daily ammonia limits (>1.9 mg/L NH~4~ as N), oxygen transfer efficiency is relatively low and results in high aeration demand [@weftec2019]. The current DO control configuration frequently over-aerates causing conditions that inhibit denitrification in downstream anoxic zones, resulting in unnecessary high chemical carbon addition demands and in a poor allocation of blower demand that leads to energy inefficiencies. Consequently, aeration accounts for 35 to 50% of BWRRF's energy consumption. There are multiple aeration control methods programmed into the supervisory control and data aquisition (SCADA) system, all of which rely on cascade control: airflow, DO, and ABAC (Table `r tab<-tab+1;config<-tab;config`). Airflow produces a constant volume of air by adjusting valves at the inlet of the aeration basin, regardless of the air demand; DO adjusts the volume of air to acheive a DO setpoint; and ABAC adjusts DO setpoints to acheive an ammonia setpoint (Figure `r fig<-fig+1;cascade<-fig;cascade`). The process variables included in the control logic ($y$), stability analysis, and forecasting model are located in one of BWRRF's three aeration basins (Figure `r fig<-fig+1;flow <- fig;flow`). 

[Table `r config`. Control configurations tested vary by which is the "control" variable (i.e., outer/master loop in cascade control), the master setpoint for the control variable, and the delay term for the master PID loop]{custom-style="Figure-Label"}

```{r table of control configurations, echo=FALSE}
configurations <- data.frame("Control Variable"=c("DO", "Ammonia", "Ammonia", "Ammonia"),
                             "Setpoint (mg/L)" = c(2.5,3.5,4.0,4.0),
                             "PID delay (s)" = c(90, 90, 90, 300),
                             row.names=c("Control", "Test 1", "Test 2", "Test 3"))
colnames(configurations) <- c("Control Variable", "Setpoint (mg/L)", "PID delay")
knitr::kable(configurations)
```


<center>
![](images/cascade-control-loop.png)
</center>

[Figure `r cascade`. Cascade control logic for ABAC at BWRRF. The reference signal $r$ is the ammonia setpoint. The difference between $r$ and the actual ammonia measurement $y_{NH_{4}}$ is input to the ammonia PID controller $C_{NH_{4}}$ which adjusts the DO setpoint. The difference between the DO setpoint and the DO measurement $y_{DO}$ is input to the DO PID controller $C_{DO}$ which adjusts the air flow setpoint. The same logic flows for the air flow controller $C_{flow}$ and air valve controller $C_{valve}$, which ultimately provides a certain volume of air to the aeration basins. A disturbance $d$, such as a change in water quality, will impact the processes $P$ within the basin as measured by $y$. The difference between the setpoints and $y$ values will force the PID controllers to continuously provide adjustments within their loop until all setpoints are met.]{custom-style="Figure-Label"}
\newline
\newline

<center>
![](images/bwrrf-flow.png)
</center>

[Figure `r flow`. Flow, zone, and sensor diagram of one of the activated sludge aeration basins at the BWRRF. Orange arrows indicate the direction of flow through the basin. Zones 4-8 are aerated and have individual DO sepoints for each zone. Red boxes indicate nitrate sensors, blue boxes indicate DO sensors used in DO control, and the purple box indicates the ammonia sensor used in ABAC control.]{custom-style="Figure-Label"}
\newline
\newline

The DO concentrations in Zones 6, 7, 8, and 9 of the aeration basins were continuously monitored using Endress Hauser (Reinach, Switzerland) COS61D optical DO sensors. In these zones, blower flowrate and valve position are also monitored and recorded in SCADA. AmmoLyt® Plus 700 ion-selective ammonia sensors from YSI (Yellow Springs, OH) are located in the aeration basin influent channel and in all three aeration basins in Zone 7. Ion-selective nitrate/nitrite sensors from YSI are located in Zones 3 and 9 of each basin; and the effluent channel after the final polishing aeration basin has an AmTax and NitraTax online analyzer (HACH, Loveland, CO). Aeration basin influent flow rates, wastewater temperature, and pH of the plant influent were also monitored. Online sensors were regularly maintained and calibrated by operations staff and readings periodically compared to laboratory results.
Data are collected and managed in the GE Proficy® system. For analysis, data was exported in 5-minute intervals into Microsoft Excel and imported to the statistical platform, $R$, for analysis. Observations that were identified as “Bad” within the Proficy system (i.e., due to sensor calibration or during power loss) were not used. For QA/QC, all Proficy exports were kept in their native format.


```{r Import data, include=FALSE}
# setwd("../Dropbox/Code/LIFT_2019/R Code")

library(xts)
library(readxl)

# This chunk takes upwards of an hour to execute, load "raw_data.RData" if avalible
if("raw_data.RData" %in% list.files(path="data")) {
  
  load(file="data/raw_data.RData")
  obj.list <- c("ab3_do", 
              "ab3_3.5",
              "ab3_4.0",
              "ab3_4.0_300",
              "ab3_4.0_300_plus")
  
} else {
  
  import_data <- "do"
  source("src/import_data.R") # ab3_do
  import_data <- "3.5 mg/L 90"
  source("src/import_data.R") # ab3_3.5
  import_data <- "4.0 mg/L 90"
  source("src/import_data.R") # ab3_4.0
  import_data <- "4.0 mg/L 300"
  source("src/import_data.R") # ab3_4.0_300
  source("src/import_historian_data.R") # ab3_4.0_300_plus
  
  obj.list <- c("ab3_do", 
                "ab3_3.5",
                "ab3_4.0",
                "ab3_4.0_300",
                "ab3_4.0_300_plus")
  
  save(list=obj.list, file="data/raw_data.RData")
}

# Homogenize and shorten column names
source("src/col_name_fix.R")

# Preserve the original 
real.data <- lapply(obj.list, function(x) get(x))
names(real.data) <- c("DO", "ABAC 3.5", "ABAC 4.0, 90s", "ABAC 4.0, 300s", "ABAC 4.0, 300s plus")
```

```{r Preprocess data, include=FALSE}
# Make column names, variable names
for(x in obj.list) {
  data <- get(x)
  colnames(data) <- make.names(colnames(data))
  assign(x, data)
}

# Add missing timestamps
for(x in obj.list) {
  time.intervals <- sapply(2:nrow(get(x)), function(i) difftime(index(get(x))[i], index(get(x))[i-1], units="mins"))
  if(length(which(time.intervals != 5)) > 0) {
    for(i in 1:length(which(time.intervals != 5))){
      start.time <- index(get(x))[which(time.intervals != 5)[i]]
      end.time <- index(get(x))[which(time.intervals != 5)[i]+1]
      new.times <- seq(start.time, end.time, by=5*60)
      new.x <- merge(get(x), new.times[2:(length(new.times)-1)], fill=NA)
      assign(x, new.x)
    }
  }
}

# Equalize number of observations in each dataset
lapply(obj.list, 
       function(x) assign(x, get(x)[(nrow(get(x)) - min(sapply(obj.list, function(x) nrow(get(x))))):nrow(get(x)),], 
                          envir = .GlobalEnv))

# Scale data
real.means <- lapply(obj.list, function(x) apply(get(x), 2, mean))
real.sd <- lapply(obj.list, function(x) apply(get(x), 2, sd))
lapply(obj.list, function(x) assign(x, scale(get(x)), envir = .GlobalEnv))
```

## Stability assessment
The goal of the stability assessment is to provide WWTP operators with a quantative metric to decide between two control configurations on the basis of variability. To measure the stability of each operating configuration holistically, we investigated two multivariate metrics of variance: Total Sample Variance (TSV) and Generalized Sample Variance (GSV). TSV is the trace of the variance-covariance matrix of $p$ variables ($trace(\Sigma)=\sigma_1^2+\sigma_2^2+...+\sigma_p^2$) and does not account for correlation between process variances. GSV is the determinant of the variance-covariance matrix ($|\Sigma|$) and will be small when there is a strong correlation between process variables. 

To compare TSV and GSV values from a pair of control configurations, the difference between and the ratio of the values were calculated. The hypothesis tests used to determine if the difference in TSV or GSV are statistically significant are:
$$H_0: TSV_i - TSV_j = 0 \text{ ; } H_1 \neq 0$$
$$H_0: GSV_i - GSV_j = 0 \text{ ; } H_1 \neq 0$$
$$H_0: TSV_i\text{ / }TSV_j = 1 \text{ ; } H_1 \neq 1$$
$$H_0: GSV_i\text{ / }GSV_j = 1 \text{ ; } H_1 \neq 1$$

## Ammonia forecast
* Training and testing datasets
* Measure model fit/accuracy

To train and test the forecasting model, the data must be aligned to simulate real-time prediction. For a dataset with *n* rows, observations $1-(n-\Delta n$) of all monitored process variables ($X_1,X_2,..,X_p$) will be merged with ($\Delta n+1)-n$ observations of the forecasted variable to create a matrix with $p+1$ columns and $n-\Delta n$ rows. Models are built using 1-6 days of process data and tested on the remaining days. Given the shortest dataset provided by BWRRF was 7.4 days, all datasets were shortened to only include 7.4 days of 5-minute level observations. The data compiled for the following analysis can be found in the [Appendix](#timeseries). All data was scaled to zero mean and unit variance for each control configuration. 

### Diurnal model
The purpose of incorporating a diurnal component into a forecasting model is to capture the time-dependent component of the response variable, in this case ammonia. While the daily trend of ammonia loading to a wastewater facility is acknowledged, it is rarely modeled (Figure 1\ref{diurnal-nh4}). The predictors in a diurnal model are various degrees (*n*) of sine and cosine functions where *t* is the minute of the day from 0 - 2$\pi$, and $\beta_i$ are fitted linear model parameters:

$$\hat{y}_t = \beta_0 + \beta_1 sin(t) + \beta_2 cos(t) + \beta_3 sin(2 \cdot t) + \beta_4 cos(2 \cdot t) + ... + \beta_{2n-1} sin(n \cdot t) + \beta_{2n} cos(n \cdot t)$$\n


```{r Plot influent ammonia, echo=FALSE, fig.align="center", fig.height=2, dpi=300}
plot.data <- real.data[[1]] # ab3_do
plot.data <- plot.data["2019-03-01/2019-03-10",which(colnames(plot.data)=="Inf NH4")]
par(mar=c(2.5,2.5,1,1), oma=c(0,2,0,2), family="serif", font=1)
plot(as.zoo(plot.data), xlab="", ylab="")
mtext("Influent ammonia (mg/L)", side=2, line=3)
```

\label{diurnal-nh4}[Figure 2: Timeseries plot of influent ammonia at the Boulder Water Resource Recovery Facility.]{custom-style="Figure-Label"}

#### Linear model
In a standard linear model, a response ($Y$) is described using a set of predictor variables ($X_1,X_2,..,X_p$) and their corresponding model parameters $\beta_0, \beta_1, ...,\beta_p$ where $\epsilon$ is an error term:
$$Y=\beta_0+\beta_1X_1+...+\beta_pX_p+\epsilon$$
Typical linear models are fit using oridinary least squares, but prediction accuracy and model interpretabililty can be improved using alterntive fitting procedures [@james2013introduction]. 

Lasso is able to select model predictors (inputs). 
Ridge regression attempts to minimize the error of predictors while simultaneously eliminating insignificant predictors. The 'shrinkage' term responsible for driving the coefficients of insigificant predictors to zero is controled by $\lambda$. When $\lambda=0$, ridge regression returns the same linear model coefficients as the more well-known ordinary least squares model. 
Cross-validation 
Adaptive lasso
Both the diurnal model and linear model were trained and tested using the `glmnet` package.

### Machine learning
* Neural network model

# Results
## Stability assessment
```{r}


# Calculate total sample variation
TSV.results <- vector()
GSV.results <- vector()
for(data in obj.list) {
  raw.data <- get(data)
  # if(length(which(apply(raw.data,2,function(x) length(unique(x))) == 1)) > 0) raw.data <- raw.data[,-which(apply(raw.data,2,function(x) length(unique(x))) == 1)]

  TSV <- sum(diag(cov(raw.data)))
  print(paste("TSV of raw",data,round(TSV,2)))
  
  GSV <- det(cov(raw.data))
  print(paste("GSV of raw",data,GSV))
  
  TSV.results <- c(TSV.results, TSV)
  GSV.results <- c(GSV.results, GSV)
}
names(TSV.results) <- c("DO", "3.5 mg/l - 90 s", "4.0 mg/L - 90 s", "4.0 mg/L - 300 s")

compare.set.variability=function(dataset1, dataset2, type, BB, title = NULL){
  #type can be one of "greater" or "not.equal"
  
  #Observed statistics
  diff.TSV.obs=sum(diag(cov(dataset1)))-sum(diag(cov(dataset2)))	
  ratio.TSV.obs=sum(diag(cov(dataset1)))/sum(diag(cov(dataset2)))	
  
  #Combinining all of the data into one set
  all.data=rbind(dataset1,dataset2)
  nn1=dim(dataset1)[1]
  nn2=dim(dataset2)[1]
  nn.total=nn1+nn2
  
  
  #Resampling
  diff.TSV.permute=array()
  ratio.TSV.permute=array()
  
  for(i in 1:BB){
    first.set=sample(1:nn.total, nn1, replace=FALSE)
    second.set=setdiff(1:nn.total, first.set)
    permute.set1=all.data[first.set,]
    permute.set2=all.data[second.set,]
    
    diff.TSV.permute[i]=sum(diag(cov(permute.set1)))-sum(diag(cov(permute.set2)))			
    ratio.TSV.permute[i]=sum(diag(cov(permute.set1)))/sum(diag(cov(permute.set2)))	
    
  }
  
  if(type=="greater"){
    
    pval.TSV.diff=length(which(diff.TSV.permute>(diff.TSV.obs)))/BB
    pval.TSV.ratio=length(which(ratio.TSV.permute>(ratio.TSV.obs)))/BB
    
  }
  # if(type=="not.equal"){
  # pval.GSV=length(which(diff.GSV.permute>abs(diff.GSV.obs)) && which(diff.GSV.permute < -abs(diff.GSV.obs)))/BB
  # pval.TSV=length(which(diff.TSV.permute>abs(diff.TSV.obs)) && which(diff.TSV.permute < -abs(diff.TSV.obs)))/BB
  # }
  
  par(mfrow=c(1,2), mar=c(2.5,2.5,2.5,0.5))
  if(!is.null(title)) par(oma=c(0,0,2,0))
  
  diff.range <- range(diff.TSV.permute)
  if(diff.TSV.obs > diff.range[2]) diff.range[2] <- diff.TSV.obs
  if(diff.TSV.obs < diff.range[1]) diff.range[1] <- diff.TSV.obs
  hist(diff.TSV.permute, breaks="FD", xlab="", ylab="", freq=F, 
       main=paste0("Difference of TSV\nObserved difference ",round(diff.TSV.obs,0)),
       xlim=diff.range)
  points(x=diff.TSV.obs, y = 0, col=2, pch=20)
  # abline(v=diff.TSV.obs, col=2, lwd=2)
  print(c(diff.TSV.obs))
  
  ratio.range <- range(ratio.TSV.permute)
  if(ratio.TSV.obs > ratio.range[2]) ratio.range[2] <- ratio.TSV.obs
  if(ratio.TSV.obs < ratio.range[1]) ratio.range[1] <- ratio.TSV.obs
  hist(ratio.TSV.permute, breaks="FD", xlab="", ylab="", freq=F, 
       main=paste0("Ratio of TSV\nObserved ratio ",round(ratio.TSV.obs,2)),
       xlim=ratio.range)
  points(x=ratio.TSV.obs, y = 0, col=2, pch=20)
  # abline(v=ratio.TSV.obs, col=2, lwd=2)
  print(c(ratio.TSV.obs))
  
  if(!is.null(title)) mtext(title, side = 3, outer = TRUE, font = 2, cex = 1.5)
  
  
  
  return(c(pval.TSV.diff, pval.TSV.ratio))
  
  
}

compare.set.variability(dataset1 = ab3_do, dataset2 = ab3_3.5, type="greater", BB=1000, title = "DO vs 3.5") # Want to reject

```


## Ammonia forecast
### Diurnal model

The initial diurnal model fit used a single sine/cosine pair. However, this approach did not capture all visible cyclic patterns. Further testing evaluated the model fit of 1 - 200 sine/cosine pairs. The best diurnal model fit for the training and testing data of each control congiuration was effectively achieved using a 6 degree diurnal model (Figure 2\ref{diurnal-rsq}). The realively low R^2^ value of the ABAC 3.5 control configuration is evident of abnormal variation in the minimum and maximum ammonia values (Figure 3\ref{z7-nh4}). 


```{r Best diurnal fit, echo=FALSE}
# Test 1 through n degrees of diurnal model fit
# 200 degrees creates a 2.8 GB file, which is unnecessary given r2 flatlines after 6-8 degrees
degrees <- 10 
diurnal.test.results <- list()

if("diurnal_fit.RData" %in% list.files(path="results")) {
  load("results/diurnal_fit.RData")
} else {
  # Initialize parallel processing
  library(doParallel)
  library(foreach)
  numCores <- detectCores()
  registerDoParallel(numCores)
  
  # For each test configuration
  for(x in obj.list) {
    obj.x <- get(x)
  
    # Convert timestamps to runtime and project onto a unit circle
    t <- 1440
    time.stamps <- difftime(index(obj.x), index(obj.x)[1], units = "mins")
    time.stamps <- as.numeric(time.stamps) %% t # Cycles are constructed
    time.stamps <- (time.stamps*360/t)*pi/180 # Cycles of minutes are converted to radians
    
    # Set training data
    predict.col <- which(colnames(obj.x) == "Z7.NH4")
    yy <- as.matrix(obj.x[,predict.col])
    xx <- as.matrix(time.stamps)
    
    # Test 1st-nth degree diurnal model
    all.degrees <- foreach(i=1:degrees,
                         .combine = 'c', .packages = c("xts","stats"), .export = c("yy","xx")) %dopar% {
                      fmla <- as.formula(paste("yy ~",paste(paste0("cos(",1:i," * xx[,1]) + sin(",1:i," * xx[,1])"),collapse=" + ")))
                      diurnal.mod <- lm(fmla)
                      return(list(diurnal.mod))
                    }
  
    ## Return model fit for each degree for each test configuration
    diurnal.test.results[[length(diurnal.test.results)+1]] <- all.degrees
    names(diurnal.test.results)[length(diurnal.test.results)] <- paste(x)
  }
  stopImplicitCluster()
  save(diurnal.test.results, file="results/diurnal_fit.RData")
}

# Extract r2 values
r.sq.vals <- lapply(diurnal.test.results, function(x) {
                unlist(lapply(x, function(y) summary(y)$r.squared))
              })
names(r.sq.vals) <- c("DO", "ABAC 3.5", "ABAC 4.0, 90s", "ABAC 4.0, 300s", "ABAC 4.0, 300s plus")

# Extract rmse
rmse.vals <- lapply(diurnal.test.results, function(x) {
                    unlist(lapply(x, function(y) sqrt(mean(y$residuals^2))))
                    })
names(rmse.vals) <- c("DO", "ABAC 3.5", "ABAC 4.0, 90s", "ABAC 4.0, 300s", "ABAC 4.0, 300s plus")

```



```{r Plot diurnal fit r2, echo=FALSE, fig.align="center", fig.fullwidth=TRUE, fig.width=6.5, fig.height=4.5, dpi=300}
# Plot r2 as a function of degree of diurnal model
plot.data <- list(r.sq.vals[[1]], r.sq.vals[[2]], r.sq.vals[[3]], r.sq.vals[[4]])

layout(matrix(data=seq(1,8), nrow=2, ncol=4, byrow = TRUE))

par(mar=c(2, 2, 2, 1) + 0.1, oma=c(3,3,0,0), cex=.9, family="serif")

# invisible(lapply(plot.data, function(x) {
for(i in 1:length(plot.data)) {
  interval <- 1:degrees
  plot(y=plot.data[[i]][interval], x=interval,
       # pch=20,
       type = "l",
       xlab="", ylab="",
       ylim=c(0,0.65),
       main= names(which(unlist(lapply(r.sq.vals, sum)) == sum(unlist(plot.data[[i]])))))
  points(y=plot.data[[i]][interval], x=interval,
         pch=20, cex=1.5)
  abline(h=max(plot.data[[i]]), col="red", cex=1.25)
  text(x=max(interval)-2,y=max(plot.data[[i]]),labels=round(max(plot.data[[i]]),2),pos=3,col="red")
  if(i==1) mtext("R-squared", side=2, line=3, outer=FALSE)
# }))
}

# Plot rmse as a function of degree of diurnal model
plot.data <- list(rmse.vals[[1]], rmse.vals[[2]], rmse.vals[[3]], rmse.vals[[4]])

for(i in 1:length(plot.data)) {
  interval <- 1:degrees
  plot(y=plot.data[[i]][interval], x=interval,
       # pch=20,
       type = "l",
       xlab="", ylab="",
       ylim=c(0.65,0.95),
       main= names(which(unlist(lapply(rmse.vals, sum)) == sum(unlist(plot.data[[i]])))))
  points(y=plot.data[[i]][interval], x=interval,
         pch=20, cex=1.5)
  abline(h=min(plot.data[[i]]), col="red", cex=1.25)
  text(x=max(interval)-2,y=min(plot.data[[i]]),labels=round(min(plot.data[[i]]),2),pos=3,col="red")
  if(i==1) mtext("RSME", side=2, line=3, outer=FALSE)
# }))
}
mtext("Degree of Diurnal Model", side = 1, line = 1, outer=TRUE, adj=0.5)
```

\label{diurnal-rsq}[Figure 3: Diurnal model fit as function of degree for each control configuration. The red line indicates the R^2^ (top) or RMSE (bottom) value for a 10th degree diurnal model, which is effectively achieved by a 6 degree or fewer diurnal model.]{custom-style="Figure-Label"}


```{r Plot Z7 NH4 for each case, echo=FALSE, fig.align="center",  fig.fullwidth=TRUE, fig.height=2.5, dpi=300}
# par(mfrow=c(1,4), mar=c(3, 1.5, 3, 1.5) + 0.1, oma=c(2,3.25,0,0), cex=0.9, family="serif")
par(mfrow=c(1,4), mar=c(2, 2, 2, 0) + 0.1, oma=c(3,3,0,0), cex=.9, family="serif")
for(i in 1:4) {
  plot.range <- (nrow(real.data[[i]]) - min(sapply(obj.list, function(x) nrow(get(x))))):nrow(real.data[[i]])
  plot(as.zoo(real.data[[i]][plot.range,"Z7 NH4"]), plot.type="multiple", main=names(real.data)[i],
       xlab="", ylab="", ylim=c(0,10))
  if(i==1) mtext("Zone 7 Ammonia (mg/L)", side = 2, line = 3, outer=FALSE, adj=0.5)
}

mtext("Date", side = 1, line = 1, outer=TRUE, adj=0.5)
```

\label{z7-nh4} [Figure 4: Timeseries plot of zone 7 ammonia at the Boulder Water Resource Recovery Facility.]{custom-style="Figure-Label"}


### Linear model
The remaining variation is modeled using a multiple linear regression model. 
```{r include=FALSE}
# Add diurnal model predictors to dataset
for(x in obj.list) {
  obj.x <- get(x)
  
  # Convert timestamps to runtime and project onto a unit circle
  t <- 1440
  time.stamps <- difftime(index(obj.x), index(obj.x)[1], units = "mins")
  time.stamps <- as.numeric(time.stamps) %% t # Cycles are constructed
  time.stamps <- (time.stamps*360/t)*pi/180 # Cycles of minutes are converted to radians
  names(time.stamps) <- "time.stamps"
  
  cos.x <- cos(time.stamps)
  names(cos.x) <- "cos.x"
  sin.x <- sin(time.stamps)
  names(sin.x) <- "sin.x"
  cos.2x <- cos(2*time.stamps)
  names(cos.2x) <- "cos.2x"
  sin.2x <- sin(2*time.stamps)
  names(sin.2x) <- "sin.2x"
  cos.3x <- cos(3*time.stamps)
  names(cos.3x) <- "cos.3x"
  sin.3x <- sin(3*time.stamps)
  names(sin.3x) <- "sin.3x"
  cos.4x <- cos(4*time.stamps)
  names(cos.4x) <- "cos.4x"
  sin.4x <- sin(4*time.stamps)
  names(sin.4x) <- "sin.4x"
  cos.5x <- cos(5*time.stamps)
  names(cos.5x) <- "cos.5x"
  sin.5x <- sin(5*time.stamps)
  names(sin.5x) <- "sin.5x"
  cos.6x <- cos(6*time.stamps)
  names(cos.6x) <- "cos.6x"
  sin.6x <- sin(6*time.stamps)
  names(sin.6x) <- "sin.6x"
  assign(x, cbind(get(x), time.stamps, cos.x, sin.x, cos.2x, sin.2x,
                  cos.3x, sin.3x, cos.4x, sin.4x, cos.5x, sin.5x, cos.6x, sin.6x), 
         envir = .GlobalEnv)
}


```

 


```{r train linear and diurnal models, eval=FALSE, fig.height=2.5, include=FALSE}
library(glmnet)
start <- Sys.time()
for(obj in obj.list) {
  
obj.data <- get(obj)
predict.col <- which(colnames(obj.data) == "Z7.NH4")

if(paste0("all-days-",obj,".RData") %in% list.files(path="results/")) {
  next
} else {

all.days <- list()
for(days in 1:7) {
  # Days to train on
  training.days <- days
  training.obs <- training.days*24*60/5
  total.obs <- nrow(obj.data)
  testing.obs <- total.obs-training.obs
  testing.days <- testing.obs/(24*60/5)
  
  all.horizons <- list()
  for(f in horizon.steps) {
    # for(i in 1:(total.obs-2*f-training.obs+1)) { # Faster to do this in an lapply loop
    testing.results <- do.call("rbind", lapply(1:(total.obs-2*f-training.obs+1), function(i) {
      # What is the forecast horizon? (given in number of steps & number of minutes )
      horizon.min <- seq(5,75,by=5)
      horizon.steps <- horizon.min/5
    
        
      # Setup training and testing data for model
      current.obs <- training.obs+f+i-1
      train.xx <- matrix(as.numeric(obj.data[i:(current.obs-f),]), nrow=length(i:(current.obs-f)), byrow=FALSE)
      train.yy <- matrix(as.numeric(obj.data[(i+f):current.obs, predict.col]), nrow=length(i:(current.obs-f)), byrow=FALSE)
      n <- intersect(which(!is.na(train.yy)), which(!apply(train.xx,1,anyNA)))
      train.xx <- train.xx[n,]
      train.yy <- train.yy[n,]
      test.xx <- matrix(as.numeric(obj.data[current.obs,]), nrow=1, byrow=FALSE)
      test.yy <- matrix(as.numeric(obj.data[(current.obs+f), predict.col]), nrow=1, byrow=FALSE)
      test.index <- index(obj.data[current.obs,])
      
      # Train diurnal model
      diurnal.terms <- c(grep("cos", colnames(obj.data)), grep("sin", colnames(obj.data)))
      mod.lm <- cv.glmnet(train.xx[,diurnal.terms],train.yy, alpha=0)
      pred.lm <- predict(mod.lm, newx=train.xx[,diurnal.terms])
      
          # Calculate training error
      SSE <- mean((train.yy-pred.lm)^2)
      SST <- mean((train.yy-mean(train.yy))^2)
      Rsqu.lm <- 1-SSE/SST;Rsqu
      RMSE.lm <- sqrt(SSE)
      
      pred.lm <- predict(mod.lm, newx=t(test.xx[,diurnal.terms]))
      
      # Train model when lambda=0 (initial parameter estimate)
      mod.ridge <- cv.glmnet(train.xx,train.yy,alpha=0)
      predict.mod.ridge <- predict(mod.ridge, newx=train.xx)
      
      # # Plot training
      # par(mar=c(3.5,3.5,1,10),xpd=TRUE, cex=0.9, family="serif")
      # plot(train.yy,ylab="",xlab="", type="l", ylim=c(min(predict.mod.ridge),max(train.yy)))
      # lines(predict.mod.ridge, col="red", lty=2)
      # mtext(side=2, line=2.5, "Scaled Ammonia")
      # mtext(side=1, line=2.5, "Observations (5 min interval)")
      # 
      # legend("right",inset=c(-.5,0),
      #        legend=c("Actual NH4","Linear Forecast\nw/ Sine Cosine"),
      #        col=c("black","red"), lty=c(1,2) ,y.intersp=1.5)
        
      # Adaptive lasso
      w3 <- 1/abs(matrix(coef(mod.ridge, s=mod.ridge$lambda.min)[, 1][-1]))^1
      set.seed(Sys.time())
      mod.adaptive <- cv.glmnet(train.xx,train.yy,alpha=1,penalty.factor=w3)
      pred.adapt <- predict(mod.adaptive,newx=train.xx, s='lambda.1se')
      
      # Calculate training error
      SSE <- mean((train.yy-pred.adapt)^2)
      SST <- mean((train.yy-mean(train.yy))^2)
      Rsqu.adapt <- 1-SSE/SST;Rsqu
      RMSE.adapt <- sqrt(SSE)
      SSE <- mean((train.yy-train.xx[,predict.col])^2)
      Rsqu.persistence <- 1-SSE/SST;Rsqu
      RMSE.persistence <- sqrt(SSE)
      
      # Forecast
      pred.adapt <- predict(mod.adaptive,newx=test.xx, s='lambda.1se')
      pred.persistence <- test.xx[,predict.col]
        
      # Save results
      # if(i==1) {
        testing.results <- data.frame("Test.time"= test.index, 
                                      "Actual.forecast" = as.numeric(test.yy),
                                      "LM.forecast" = as.numeric(pred.adapt),
                                      "Persistence.forecast" = as.numeric(pred.persistence),
                                      "Training.R2.LM" = as.numeric(Rsqu.adapt),
                                      "Training.RMSE.LM" = as.numeric(RMSE.adapt),
                                      "Diurnal.forecast" =as.numeric(pred.lm),
                                      "Training.R2.D"=as.numeric(Rsqu.lm),
                                      "Training.RMSE.D"=as.numeric(RMSE.lm))
      # } else {
      #   testing.results <- rbind(testing.results, 
      #                            data.frame("Test.time"= test.index, 
      #                                 "Actual.forecast" = as.numeric(test.yy),
      #                                 "LM.forecast" = as.numeric(pred.adapt),
      #                                 "Persistence.forecast" = as.numeric(pred.persistence),
      #                                 "Training.R2.LM" = as.numeric(Rsqu.adapt),
      #                                 "Training.RMSE.LM" = as.numeric(RMSE.adapt),
      #                                 "Diurnal.forecast" =as.numeric(pred.lm),
      #                                 "Training.R2.D"=as.numeric(Rsqu.lm),
      #                                 "Training.RMSE.D"=as.numeric(RMSE.lm)))
      # }
      # print(paste("Completed", obj, days, f, i,"in",(total.obs-2*f-training.obs+1)))
      return(testing.results)
    }))
    all.horizons[[length(all.horizons)+1]] <- testing.results
    print(paste("Completed", obj, days, f))
}
all.days[[length(all.days)+1]] <- all.horizons
}
assign(paste0("all.days.",obj), all.days)
save(list=paste0("all.days.",obj), file=paste0("results/all-days-",obj,".RData"))
rm(list=paste0("all.days.",obj))
}
}
end <- Sys.time()
end-start
```







```{r diurnal/linear rmse comparison, eval=FALSE, fig.height=2.5, include=FALSE}
# Load all compiled data
all.days.files <- sapply(list.files("results/",pattern="all-days-"), function(x) load(paste0("results/",x), envir=.GlobalEnv))

for(file in all.days.files) {
  all.days <- get(file)
  
  # Collect diurnal model data
for(days in 1:7) {
  obj.data <- all.days[[days]][[1]]
  for(step in 1:15) {
    results <- obj.data[[step]]
    rmse.m <- sqrt(mean((results$Diurnal.forecast-results$Actual.forecast)^2))
    rmse.p <- sqrt(mean((results$Persistence.forecast-results$Actual.forecast)^2))
    
    # Calculate training error
    SSE <- mean((results$Actual.forecast-results$Diurnal.forecast)^2)
    SST <- mean((results$Actual.forecast-mean(results$Actual.forecast))^2)
    Rsqu.m <- 1-SSE/SST
    SSE <- mean((results$Actual.forecast-results$Persistence.forecast)^2)
    Rsqu.p <- 1-SSE/SST
    
    if((days==1) && (step==1)) {
      rmse.comparison <- matrix(c(days, step*5, rmse.m, rmse.p, Rsqu.m, Rsqu.p), nrow=1)
    } else {
      rmse.comparison <- rbind(rmse.comparison, matrix(c(days, step*5, rmse.m, rmse.p, Rsqu.m, Rsqu.p), nrow=1))
    }
  }
}
colnames(rmse.comparison) <- c("Training Window", "Forecast Horizon", "Model RMSE", "Persistence RMSE", "Model R2", "Persistence R2")
rmse.comparison.lm <- rmse.comparison


# Collect diurnal+linear model data
for(days in 1:7) {
  obj.data <- all.days[[days]][[1]]
  for(step in 1:15) {
    results <- obj.data[[step]][[1]]
    # results <- xts(results[,-1], order.by = results[,1])
    rmse.m <- sqrt(mean((results$LM.forecast-results$Actual.forecast)^2))
    rmse.p <- sqrt(mean((results$Persistence.forecast-results$Actual.forecast)^2))
    
    # Calculate training error
    SSE <- mean((results$Actual.forecast-results$LM.forecast)^2)
    SST <- mean((results$Actual.forecast-mean(results$Actual.forecast))^2)
    Rsqu.m <- 1-SSE/SST
    SSE <- mean((results$Actual.forecast-results$Persistence.forecast)^2)
    Rsqu.p <- 1-SSE/SST
    
    if((days==1) && (step==1)) {
      rmse.comparison <- matrix(c(days, step*5, rmse.m, rmse.p, Rsqu.m, Rsqu.p), nrow=1)
    } else {
      rmse.comparison <- rbind(rmse.comparison, matrix(c(days, step*5, rmse.m, rmse.p, Rsqu.m, Rsqu.p), nrow=1))
    }
  }
}
colnames(rmse.comparison) <- c("Training Window", "Forecast Horizon", "LM RMSE", "Persistence RMSE", "Model R2", "Persistence R2")
rmse.comparison.adapt <- rmse.comparison



# RMSE and R2 vs Forecast Horizon by Training Window (grouped plots)
line.colors <- rainbow(7)
mat <- matrix(c(1,2,3,4,4,5),2,3, byrow = TRUE)
layout(mat, widths=c(.35,.35,.3), heights = c(0.95,.05))
par(mar=c(3.5, 3.5, 0, .5) + 0.1, oma=c(0,0,0,0), cex=.9, family="serif")
plot(x=unique(rmse.comparison.adapt[,2]), 
       y=sapply(unique(rmse.comparison.adapt[,2]), function(x) mean(rmse.comparison.adapt[which(rmse.comparison.adapt[,2]==x),4])), type="l",
     xlab="", ylab="", col="black", lwd=2, lty=2)

for(i in 1:7) {
  lines(x=rmse.comparison.adapt[which(rmse.comparison.adapt[,1]==i),2], 
   y=rmse.comparison.adapt[which(rmse.comparison.adapt[,1]==i),3], type="l",
   xlab="", ylab="", col=line.colors[i], lwd=2)
}

for(i in 1:7) {
  lines(x=rmse.comparison.lm[which(rmse.comparison.lm[,1]==i),2], 
   y=rmse.comparison.lm[which(rmse.comparison.lm[,1]==i),3], type="l",
   xlab="", ylab="", col=line.colors[i], lwd=2, lty=3)
}

mtext("RMSE", side = 2, line = 2.5, outer=FALSE, adj=0.5)


plot(x=unique(rmse.comparison.adapt[,2]), 
       y=sapply(unique(rmse.comparison.adapt[,2]), function(x) mean(rmse.comparison.adapt[which(rmse.comparison.adapt[,2]==x),6])), type="l",
     xlab="", ylab="", col="black", lwd=2, lty=2)

for(i in 1:7) {
  lines(x=rmse.comparison.adapt[which(rmse.comparison.adapt[,1]==i),2], 
   y=rmse.comparison.adapt[which(rmse.comparison.adapt[,1]==i),5], type="l",
   xlab="", ylab="", col=line.colors[i], lwd=2)
}

for(i in 1:7) {
  lines(x=rmse.comparison.lm[which(rmse.comparison.lm[,1]==i),2], 
   y=rmse.comparison.lm[which(rmse.comparison.lm[,1]==i),5], type="l",
   xlab="", ylab="", col=line.colors[i], lwd=2, lty=3)
}
mtext("R-squared", side = 2, line = 2.5, outer=FALSE, adj=0.5)

par(mar=c(0, 0, 0, 0))
plot(0, type="n", axes=FALSE, xlab="", ylab="", xlim=c(0, 10), ylim=c(0, 10))
legend("center",
    legend=c("Persistence", paste(unique(rmse.comparison.adapt[,1]), "day")),
    col=c("black",line.colors), lty=c(2, rep(1,7)), xpd = TRUE
    )

plot(0, type="n", axes=FALSE)
mtext("Forecast Horizon (min)")

plot(0, type="n", axes=FALSE)
  
}






```



```{r Timeseries of diurnal and linear forecasts, eval=FALSE, include=FALSE}

all.days <- all.days # change later when each file is declared

# Forecasted values
for(days in 1:7) {
  obj.data <- all.days[[days]][[1]]
  results <- obj.data[[1]]
  plot(results$Actual.forecast, type="l", lty=2)
  lines(results$Diurnal.forecast, lty=1, col="black")
  step.color <- rainbow(15)
  for(step in 1:15) {
    results <- obj.data[[step]]
    lines(results$LM.forecast, lty=1, col=step.color[step])
  }
}


# Model error
for(days in 1:7) {
  obj.data <- all.days[[days]][[1]]
  results <- obj.data[[1]]
  plot(results$Training.R2.D, type="l", ylim=c(0,1))
  step.color <- rainbow(15)
  for(step in 1:15) {
    results <- obj.data[[step]]
    lines(results$Training.R2.LM, lty=1, col=step.color[step])
  }
}
```



```{r eval=FALSE, include=FALSE}

# I CAN'T GET MANDY'S WAY TO WORK!!!!
# # Train diurnal model
# source("src/diurnal_train_and_test.R")
# n <- 1:(current.obs-i) # training observations
# mod.lm <- diurnal.train(data=obj.data[n,], predict.col)
# 
# # Update response variables with diurnal forecast
# nh4.actual <- obj.data[,predict.col]
# nh4.residuals <- calc.residuals(obj.data, predict.col, mod.lm)
# 
# # Setup training and testing data for linear model
# ## Remove sine, cosine, and timestamps
# terms <- c(grep("cos", colnames(obj.data)), grep("sin", colnames(obj.data)), grep("time.stamps", colnames(obj.data)))
# train.xx <- obj.data[,-c(predict.col,terms)]
# ## Replace actual ammonia with diurnally-adjusted ammonia
# train.xx <- cbind(nh4.residuals, train.xx)
# colnames(train.xx)[1] <- "Z7.NH4.residuals"
# ## Separate train and test predictor variables
# test.n <- (last(n)+1)
# test.xx <- train.xx[test.n,]
# train.xx <- train.xx[n,]
# ## Align i-step-head residuals
# train.yy <- nh4.residuals[n+i]
# 
# # Train linear model
# mod.ridge <- cv.glmnet(matrix(as.numeric(train.xx), ncol=ncol(train.xx), byrow=FALSE),
#                        matrix(as.numeric(train.yy), ncol=ncol(train.yy), byrow=FALSE),
#                        alpha=0)
# 
# # Forecast ammonia residuals
# nh4.lm.residuals <- predict(mod.ridge, newx = matrix(as.numeric(test.xx), nrow=1, byrow=FALSE))
# nh4.forecast <- nh4.lm.residuals + nh4.residuals[test.n+1]
# nh4.forecast
# nh4.actual[test.n+1]
# 




# Initialize parallel processing
library(doParallel)
library(foreach)
numCores <- detectCores()
registerDoParallel(numCores)
# for(x in obj.list) {
lm.results <- foreach(obj.data=lapply(obj.list, get), 
                      .combine = 'c', .packages = c("xts","stats","glmnet")) %dopar% {
  
  # Days to train on
  training.days <- 3
  training.obs <- training.days*24*60/5 
  total.obs <- nrow(obj.data)
  testing.obs <- total.obs-training.obs
  testing.days <- testing.obs/(24*60/5)
  
  # What is the forecast horizon? (given in number of steps & number of minutes )
  horizon.min <- seq(5,75,by=5)
  horizon.steps <- horizon.min/5

  predict.col <- which(colnames(obj.data) == "Z7.NH4")
  time.col <- which(colnames(obj.data) == "time.stamps")
  diurnal.1 <- which(colnames(obj.data) == "cos.x")
  diurnal.2 <- which(colnames(obj.data) == "sin.x")
  diurnal.3 <- which(colnames(obj.data) == "cos.2x")
  diurnal.4 <- which(colnames(obj.data) == "sin.2x")
  diurnal.5 <- which(colnames(obj.data) == "cos.3x")
  diurnal.6 <- which(colnames(obj.data) == "sin.3x")
  diurnal.7 <- which(colnames(obj.data) == "cos.4x")
  diurnal.8 <- which(colnames(obj.data) == "sin.4x")
  diurnal.9 <- which(colnames(obj.data) == "cos.5x")
  diurnal.10 <- which(colnames(obj.data) == "sin.5x")
  diurnal.11 <- which(colnames(obj.data) == "cos.6x")
  diurnal.12 <- which(colnames(obj.data) == "sin.6x")
  
  # Set of things to save through the loop
  model_obj.data <- matrix(NA, nrow=testing.obs, ncol=length(horizon.min))
  persistence_obj.data <- matrix(NA, nrow=testing.obs, ncol=length(horizon.min))
  true_obj.data <- matrix(NA, nrow=testing.obs, ncol=length(horizon.min))
  
  RsqDir_obj.data <- matrix(NA, nrow=testing.obs, ncol=length(horizon.min))
  RsqAdp_obj.data <- matrix(NA, nrow=testing.obs, ncol=length(horizon.min))

  ################################################################
  #Loop over the forecast horizon, index goes i=1,2,3,...,14,15
  ################################################################
  for(i in 1:length(horizon.steps)){
  	print(paste("i, horizon step is", i, sep=" "))
  	
  	#Obtaining the persistence forecast for each horizon
  	#slots says where to put the persistence forecasts in the matrix to save
  	slots=1:(testing.obs-i+1)
  	persistence_obj.data[slots,i]=obj.data[(training.obs):(total.obs-i),predict.col]
  	true_obj.data[slots,i]=obj.data[(training.obs+i):total.obs,predict.col]
  	
  	################################################################
  	#Loop over the observations to make predictions, index goes j=1:#testing obs-horizon+1
  	################################################################
  	for(j in 1:(testing.obs-i+1)){
  		if(j%%100==0){print(paste("j, forecast observation is", j, sep=" "))}
  
  		train.data=obj.data[(j):(j+training.obs-2),]
  		print(paste("Training data:", paste(range(index(train.data)), collapse=" ")))
  		
  		#Index of current observation
  		curr.index=j+training.obs-1
  		print(paste("Current obs:", paste(index(obj.data[curr.index,]))))
  		
  		#Index of observation to forecast
  		fore.index=j+training.obs-1+i
  		print(paste("Forecast:", paste(index(obj.data[fore.index,]))))
  		
  		###########################
  		##MODELING STEP #1
  		##Estimate diurnal trend of these 7 days
  		###########################
  		#Grabbing the columns of the response and cosine/sine terms
  		yy=train.data[,predict.col]
  		x1=train.data[,diurnal.1]
  		x2=train.data[,diurnal.2]
  		x3=train.data[,diurnal.3]
  		x4=train.data[,diurnal.4]
  		x5=train.data[,diurnal.5]
  		x6=train.data[,diurnal.6]
  		x7=train.data[,diurnal.7]
  		x8=train.data[,diurnal.8]
  		x9=train.data[,diurnal.9]
  		x10=train.data[,diurnal.10]
  		x11=train.data[,diurnal.11]
  		x12=train.data[,diurnal.12]
  		
  		#sum(complete.cases(yy))
  		diurnal.train=lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, na.action=na.exclude)
  		Rsq.diurnal=summary(diurnal.train)$r.squared  #to save R^2 of diurnal model on training set
  		RsqDir_obj.data[j,i]=Rsq.diurnal
  		
  		#Forecast from diurnal model for step ahead
		  diurn.fore=diurnal.train$coef%*%c(1,obj.data[fore.index,diurnal.1:diurnal.12])
  	  
		  #Level 1 residuals
  		train.res1=yy-predict(diurnal.train)
  	
  		###########################
  		##MODELING STEP #2
  		##Fit residuals of diurnal model with lagged values of covariates and lagged value of residual of response
  		###########################
  		
  		#Creating the predictor matrix, removing timestamp and cosine/sine terms
  		# XX=cbind(train.res1,train.data[,-c(time.col, diurnal.1:diurnal.12)])
  		# colnames(XX)[1]="Z9.NH4.residual"
  		# nn.XX=dim(XX)[1]
  		XX <- train.data
  		
  		#Lag covariates
  		# train.yy=train.res1[(i+1):nn.XX]
  		# colnames(train.yy)[1]="Z9.NH4.residual"
  		train.yy <- yy[(i+1):nn.XX]
  		train.xx=XX[1:(nn.XX-i),]
  		
  		#Remove missing values 
  		# all.vars=cbind(train.yy,train.xx)
  		# index.present=complete.cases(all.vars)
  		index.present <- intersect(which(!is.na(train.yy)), which(!apply(train.xx, 1, anyNA)))
  		train.yy=as.numeric(train.yy[index.present])
  		train.xx=as.matrix(train.xx[index.present,])	
  	
  		set.seed(i*j)
  		mod.ridge=cv.glmnet(train.xx,train.yy,alpha=0)
  		weight = 1/abs(matrix(coef(mod.ridge, s=mod.ridge$lambda.min)[, 1][-1]))^1
  		mod.adaptive = cv.glmnet(train.xx, train.yy,  alpha=1, penalty.factor=weight)
  		adapt.coef=coef(mod.adaptive, s=mod.adaptive$lambda.1se)
  		
  		pred.adapt=predict(mod.adaptive,newx=train.xx, s='lambda.min')
		  SSE=mean((train.yy-pred.adapt)^2);SSE
  		SST=mean((train.yy-mean(train.yy))^2);SST
  		Rsqu=1-SSE/SST
  		
  		RsqAdp_obj.data[j,i]=Rsqu
  		
  		explain=(1-Rsq.diurnal)*Rsqu
  		Rsq.diurnal+explain
  		
  		train.res2=train.yy-pred.adapt  
  		
  		#Forecast the residual piece
  		current.diurnal.residual=obj.data[curr.index,predict.col]-diurnal.train$coef%*%c(1,obj.data[curr.index,diurnal.1:diurnal.12])
  		
  		
  		# current.xx=t(as.matrix(c(as.numeric(current.diurnal.residual),as.numeric(obj.data[curr.index,-c(time.col, diurnal.1:diurnal.12)]))))
  		# colnames(current.xx)
  		current.xx<-as.matrix(obj.data[curr.index,])
  		
  		XX.fore=predict(mod.adaptive,newx=current.xx, s='lambda.1se')
  		
  		# model_obj.data[j,i]=diurn.fore+XX.fore
  		model_obj.data[j,i]=XX.fore
  	}
  }
  return(list(list(model_obj.data,
              persistence_obj.data,
              true_obj.data,
              RsqDir_obj.data, 
              RsqAdp_obj.data)))
}

names(lm.results) <- obj.list

for(model in lm.results) {
  rmse.mod=array()
  rmse.per=array()
  
  for(i in 1:15){
  	replace=which(model[[1]][,i]<0);print(replace)
  	model[[1]][replace,i]=rep(0,length(replace))
  	rmse.mod[i]=sqrt(mean((model[[1]][,i]-model[[3]][,i])^2,na.rm=TRUE))
  	rmse.per[i]=sqrt(mean((model[[2]][,i]-model[[3]][,i])^2,na.rm=TRUE))
  }

  plot(horizon.min, rmse.mod, type="b",pch=19,col=1, xlab="",ylab="", ylim=c(0,1.1))
  lines(horizon.min, rmse.per, type="b",pch=17, col=2)
  title("Model Comparison", xlab="Forecast Horizon (Minutes)", ylab="RMSE", cex.main=1.75, cex.lab=1.4)
  legend(5,1.1, c("Linear Model", "Persistence"), pch=c(19,17), col=c(1,2), lty=c(1,1), bty="n",cex=1.5)

  avg.dir=array()
  avg.lin=array()
  avg.tot=array()
  
  for(i in 1:15) {
  	avg.dir[i]=mean(model[[4]][,i], na.rm=TRUE)
  
  	explain=(1-model[[4]][,i])*model[[5]][,i]
  	tot.Rsq=model[[4]][,i]+explain
  
  	avg.lin[i]=mean(explain,na.rm=TRUE)
  	avg.tot[i]=mean(tot.Rsq,na.rm=TRUE)
  }
  
  plot(horizon.min, avg.dir, type="b",pch=19,col=3, xlab="",ylab="", ylim=c(0,1.1))
  lines(horizon.min, avg.lin, type="b",pch=17,col=4)
  lines(horizon.min, avg.tot, type="b",pch=18,col=2)
  title("Model Component R^2", xlab="Forecast Horizon (Minutes)", ylab="Rsqu", cex.main=1.75, cex.lab=1.4)
  legend(5,0.3, c("Diurnal", "Adaptive", "Total"), pch=c(19,17,18), col=c(3,4,2), lty=c(1,1,1), bty="n",cex=1.5)
}




# 
# 
# plot(1:1152, true_obj.data[,15],type="l",col=1)
# lines(1:1152, model_obj.data[,15],type="l",col=2)
# 
# 
# min(true_obj.data[,15], na.rm=T)
# min(model_obj.data[,15], na.rm=T)
```



# Appendix
## Timeseries {#timeseries}
```{r Timeseries plots, fig.height=9, fig.width=6.5, fig.align="center", echo=FALSE}
par(cex=.9, family="serif")
for(i in 1:length(real.data)) {
  plot.range <- (nrow(real.data[[i]]) - min(sapply(obj.list, function(x) nrow(get(x))))):nrow(real.data[[i]])
  plot(as.zoo(real.data[[i]][plot.range,]), plot.type="multiple", main=names(real.data)[i],
       xlab="Date")
}
```

